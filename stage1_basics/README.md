## Stage 1 — Baby Steps: "I need a starter script that actually runs."

Goal: Understand the *shape* of a transformer workflow without caring how it works internally.

Tasks:

1. **Write a super simple notebook/script:**

   * Load CIFAR-10 or MNIST (keep it tiny)
   * Use a pre-trained Vision Transformer (`vit_b_16`)
   * Fine-tune the head for 10 classes
   * Train for like 3–5 epochs
   * Plot loss curves
   * Save the model

You'll learn:

* Model definition
* Training loop
* Dataloaders
* Optimizers
* Forward/backward passes

This is the "just get reps in" stage.

<br>
